{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EPA1333 - Computer Engineering for Scientific Computing\n",
    "## Week 6 - Oct 10, 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Python Data Science Handbook**\n",
    "\n",
    "*Jake VanderPlas*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import Image\n",
    "Image('https://covers.oreillystatic.com/images/0636920034919/lrg.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cheat Sheets\n",
    "\n",
    "[Mark Graph](http://markthegraph.blogspot.nl/) has created some cheat sheets for Python, Matplotlib and Pandas. You can download them from here: http://bit.ly/python_cs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas\n",
    "\n",
    "Build on top of NumPy. It provides high-level data structures and manipulation tools \n",
    "for data analysis. \n",
    "\n",
    "  * Labeled axes\n",
    "  * Arithmetic operations and reductions\n",
    "  * Flexible handling of missing data\n",
    "  * Time Series\n",
    "\n",
    "The main datastructures are: **Series** and **DataFrame**\n",
    "\n",
    "\n",
    "\n",
    "### Documentation\n",
    "  * http://pandas.pydata.org/\n",
    "  * http://pandas.pydata.org/pandas-docs/stable/10min.html\n",
    "  \n",
    "  * Google\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Series\n",
    "\n",
    "A one-dimensional array-like object and an index.\n",
    "\n",
    "s = Series( [1, 2, 3, 4], index=['A', 'B', 'C', 'D'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With a list. Explicitly providing the index\n",
    "s = pd.Series( [1, 2, 3, 4], index=['A', 'B', 'C', 'D'])\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With a numpy array.\n",
    "s = pd.Series( np.random.randn(5) )\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With a dict\n",
    "cities = { 'Amsterdam' : 1000, 'Utrecht' : 2000, 'The Hague' : 3000, 'Rotterdam' : 4000}\n",
    "s = pd.Series( cities )\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Name the index and the series\n",
    "s.name = 'Code'\n",
    "s.index.name = 'Cities'\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accessing the index\n",
    "s.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accessing the values\n",
    "s.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indexing on position. Result is a value.\n",
    "s[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slicing on position. Result is another Series\n",
    "s[1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indexing on label (index)\n",
    "s['Rotterdam']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slicing on label\n",
    "# Note, when slicing on label the slice is INCLUDING the end.\n",
    "s[:'Rotterdam']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Be careful when label is integers too... \n",
    "s2 = pd.Series( range(5), index=[3,2,4,0,1])\n",
    "s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This will select the label, not the position\n",
    "s2[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slicing will select on position!\n",
    "s2[1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fancy indexing\n",
    "s[ ['Utrecht', 'Amsterdam'] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check for values\n",
    "s.isin([1000, 1500, 2500, 3000, 'Monkey'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for index \n",
    "'Utrecht' in s, 'Maastricht' in s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering and NumPy universal functions work as aspected\n",
    "s[ s >= 2500 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s * 2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log( s )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Count the values in a Series\n",
    "s2 = pd.Series( np.random.randint(10, size=100) )\n",
    "s2.value_counts( sort=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique values only\n",
    "s2 = pd.Series( ['a','b','c','a','d','b','g','d','g','g','c','e'])\n",
    "s2.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NaN values\n",
    "\n",
    "NaN values (Not a Number) represent missing values or NA values in the Pandas library.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2 = pd.Series( [ 1500, 500, np.nan, 10], index=['Maastricht', 'Groningen', 'Assen', 'Haarlem'])\n",
    "s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check for NaN values \n",
    "pd.isnull(s2) \n",
    "\n",
    "#s2.isnull()    # As an object method also works\n",
    "\n",
    "#pd.notnull(s2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change a value\n",
    "s2['Haarlem'] = 3500\n",
    "s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new value\n",
    "s2['Utrecht'] = 222\n",
    "s2['Amsterdam'] = 333\n",
    "s2['Rotterdam'] = 444\n",
    "s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Addition is done based on index. NaN if no matching index found.\n",
    "s + s2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrame\n",
    "\n",
    "A DataFrame is a table/spreadsheet with rows and columns that can contain different types of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using a matrix\n",
    "df = pd.DataFrame( np.random.random( size=(3,4) ), \n",
    "                      columns=list(\"ABCD\"), \n",
    "                      index=['first', 'second','third'] )\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using a dictionary\n",
    "d = { 'A' : range(30,37,3),\n",
    "      'B' : np.random.random(3),\n",
    "      'C' : [ random.random() for _ in range(3) ],\n",
    "      'D' : ['John', 'Mary', 'Jane']\n",
    "    }\n",
    "df = pd.DataFrame( d, index=['first','second','third'] )\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generic info\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Statistics on the numerical data\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Accessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting column, result is Series\n",
    "df['B']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative, result is Series\n",
    "df.B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fancy indexing, result is dataframe\n",
    "df[ ['D','B'] ]\n",
    "\n",
    "#df[ ['B'] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting rows, result is series\n",
    "df.ix[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slicing, result is dataframe\n",
    "df.ix[ 1:2 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting elements [row, column]\n",
    "df.ix[1,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With slicing\n",
    "df.ix[1:3, :3 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fancy indexing, using positions\n",
    "# Warning: watch out if labels are integers too! \n",
    "# Use df.iloc and df.loc to use positions or labels explicitly.\n",
    "# df.ix does a smart guess, but prioritizes labels.\n",
    "df.ix[:2, [3,0,2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fancy indexing, using labels!\n",
    "df.ix[ :'second', ['D', 'A', 'C'] ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's print df again\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Selecting values. Not matching values are replaced by NaN\n",
    "df[df < 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting rows based on a Series of booleans\n",
    "df[ df.D == 'Mary']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing values\n",
    "df.ix['first','A'] = 28\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a new column\n",
    "df['E'] = 500\n",
    "df['F'] = np.sqrt(df['A'])\n",
    "df['G'] = df['B'] / df['C']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reindexing a dataframe with ix\n",
    "# Change the order of the index / columns and add new ones\n",
    "df.ix[ ['third','first','second','fourth'], ['D','E','A','H','F','B','C','G']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping entries. Drop a row\n",
    "df.drop(['second'], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop a column (or 2)\n",
    "df.drop( ['B','F'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arithmetic\n",
    "\n",
    "NumPy universal functions still work as expected. Aggregation as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame( np.arange(9).reshape(3,3), columns=list(\"abc\"),\n",
    "                  index=[\"John\",\"Mary\",\"Peter\"])\n",
    "df2 = pd.DataFrame( np.arange(12).reshape(4,3), columns=list(\"acd\"),\n",
    "                  index=[\"Anne\", \"John\", \"Mary\", \"Zach\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Addition matches both index and column, NaN for all other index, column combinations\n",
    "df1 + df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Addition with fill-values\n",
    "# Only if value is not in df1 and df2 will NaN appear.\n",
    "df1.add(df2, fill_value=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Universal functions, element wise\n",
    "\n",
    "np.sqrt(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregation, sum per column\n",
    "df2.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sum per row\n",
    "df2.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cumulative sums\n",
    "df2.cumsum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other functions that are available include:\n",
    "  * count - count non-NA values\n",
    "  * min/max\n",
    "  * argmin, argmax - location of min/max value (Series)\n",
    "  * idxmin, idxmax - index values of min/max (DataFrame)\n",
    "  * sum, mean, var, std\n",
    "  * cumsum, cumprod, cummin, cummax - cumulative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorting and Rank\n",
    "\n",
    "Sorting can be done on rows (index) and columns.\n",
    "\n",
    "  * sort_index\n",
    "  * sort_values\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort rows\n",
    "df.sort_index(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort rows, based on the values in a column\n",
    "df.sort_values( by='B', ascending=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Sort columns\n",
    "df.sort_index(ascending=False, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting series on index\n",
    "s = pd.Series( np.random.randint( 10, size=5) )\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.sort_index( ascending=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting the values of the Series\n",
    "s.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ranking values\n",
    "# method = average, first, min, max \n",
    "s.rank(method='average')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ranking in a dataframe\n",
    "# First drop column D as it contains strings.\n",
    "df.drop('D', axis=1).rank(method='first', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling missing data\n",
    "\n",
    "Missing data is represented as NaN. There are ways to detect and deal with these\n",
    "values.\n",
    "  * isnull() / notnull() - test for NaN\n",
    "  * dropna() - leave out NaN\n",
    "  * fillna() - replace NaN with a value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import NaN as NA\n",
    "\n",
    "d = pd.Series( [1, NA, 3.5, NA, 7])\n",
    "\n",
    "d.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d[d.notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropna on dataframes drops entire rows/columns\n",
    "df = pd.DataFrame( np.random.rand(3,4) )\n",
    "df.ix[:,2] = NA\n",
    "df.ix[0,2:] = NA\n",
    "df.ix[2,0] = NA\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop entire row/column (axis) / how=\"all\" or \"any\"\n",
    "df.dropna(axis=1, how=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling in data\n",
    "\n",
    "df.fillna( 1000 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or fill in with data from the dataframe\n",
    "# Fill data per row or column (axis) \n",
    "# and forward / backward fill (method)\n",
    "df.fillna( axis=1, method=\"ffill\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a mean value (of each column)\n",
    "df.fillna(df.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Reading / Writing\n",
    "\n",
    "There are easy ways to read/write dataframes. Read the manual for all the possible\n",
    "arguments that you can provide to easy parsing the data.\n",
    "\n",
    "  * read_csv\n",
    "  * read_excel\n",
    "  * read_clipboard\n",
    "  \n",
    "  * to_csv\n",
    "  * to_excel\n",
    "  * to_clipboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On Linux/Msc: !cat 'csv_example.csv'\n",
    "!type csv_example.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also supports URLs directly.\n",
    "df = pd.read_csv('csv_example.csv', delimiter=',', skipinitialspace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handy if you copy from the web\n",
    "pd.read_clipboard(sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.to_csv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Wrangling (Ch 7)\n",
    "\n",
    "Combining and merging data sets\n",
    "\n",
    "  * merge\n",
    "  * concat\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "city_names = ['Amsterdam','Utrecht','Haarlem','Maastricht',\n",
    "              'Rotterdam','Groningen','Assen','The Hague']\n",
    "province_names = ['NH','UT','NH','LI','ZH','GR','DR','ZH']\n",
    "\n",
    "\n",
    "cities = pd.DataFrame( { 'City':city_names, 'Province':province_names })\n",
    "cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame( {'Name':['Alice', 'Steven', 'Karen'],\n",
    "                     'City':['Haarlem','Assen','Rotterdam'],\n",
    "                     'Age':[23,33,40]}, columns=[\"Name\",\"City\",\"Age\"])\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat will concatenate 2 dataframes\n",
    "# Watch the index!\n",
    "people = pd.concat( [df,df2], ignore_index=True, axis=0)\n",
    "people"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge will combine 2 dataframes by combining rows from both dataframes if they match\n",
    "on a certain column value (or set of column values).\n",
    "\n",
    "What happens to rows in either dataframe if no matching row is found depends on the \"how\" argument:\n",
    "  * inner: only rows that match will be in the result (default)\n",
    "  * outer: rows in either dataframe that don't match are also included in the result (with NaN)\n",
    "  * left: rows in the left dataframe that don't match are also included in the result\n",
    "  * right: rows in the right dataframe that don't match are also included in the result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# We can combine people and cities... merge\n",
    "# on - what columns should match?\n",
    "# how - what should be done with non-matching entries? (left, right, outer, inner)\n",
    "pd.merge( people, cities, on=\"City\", how=\"outer\" )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting (Ch 8)\n",
    "\n",
    "matplotlib can create plots. However, Series and DataFrames provide shortcuts\n",
    "to calling matplotlib.\n",
    "\n",
    "  * Series.plot\n",
    "  * Dataframe.plot\n",
    "  \n",
    "Any arguments are passed through to matplotlib.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series( np.random.rand(10).cumsum() )\n",
    "s.index.name=\"X-Axis-label\"\n",
    "s.plot(kind=\"line\", title=\"Series Plot\", label=\"line\", legend=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame( np.random.randn(10,4).cumsum(axis=0), columns=list(\"ABCD\"),\n",
    "    index=np.arange(0,100,10))\n",
    "df.index.name=\"Index Name\"\n",
    "df.columns.name=\"Column Names\"\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(kind=\"line\", style=\"-o\", title=\"DataFrame Plot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: students and grades again\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# students and their studnr\n",
    "names=['John','Mary','Jane','Anne','Peter','Bob','Carol','Zach','David','Iris','Sarah','Charlie','Eve','George']\n",
    "studnr=np.random.randint(100000, 999999, size=(len(names)))\n",
    "\n",
    "student = pd.DataFrame( {'Name':names, 'Studnr':studnr })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate a set of grades\n",
    "def gen_grades( ids, nrgrades, course ):\n",
    "    # Generate a list of indexes of ids for which we generate grades\n",
    "    ids_index = np.random.choice(len(ids), size=nrgrades, replace=False )\n",
    "\n",
    "    # Find the corresponding studnr\n",
    "    chosen_ids = ids[ ids_index ]\n",
    "\n",
    "    # Generate some grades for the exam and retake\n",
    "    grades=[ float(\"%.1f\" % g) for g in np.random.rand(nrgrades)*6 + 4 ]\n",
    "\n",
    "    grade_table = pd.DataFrame( {'Studnr':chosen_ids, 'Course':course, 'Grade': grades }, \n",
    "                    columns=['Studnr', 'Course', 'Grade'])\n",
    "\n",
    "    return grade_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 4 test grade results for three courses\n",
    "all_grades = []\n",
    "\n",
    "for course in ['EPA101', 'EPA202', 'EPA303']:\n",
    "    for test in ['Test1','Test2','Test3','Test4']:\n",
    "        grades = gen_grades( studnr, 12, course)\n",
    "        grades.columns = ['Studnr','Course', test]\n",
    "    \n",
    "        all_grades.append(grades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "len(all_grades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_grades[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Merge the test results of all courses into one DataFrame\n",
    "all_grades[0].merge(all_grades[1],how=\"outer\").\\\n",
    "    merge(all_grades[2],how=\"outer\").\\\n",
    "    merge(all_grades[3],how=\"outer\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's do them all\n",
    "grades_per_course = []\n",
    "\n",
    "for i in range(0,9,4):\n",
    "    g = all_grades[i].merge(all_grades[i+1],how=\"outer\").\\\n",
    "        merge(all_grades[i+2],how=\"outer\").\\\n",
    "        merge(all_grades[i+3],how=\"outer\")\n",
    "    grades_per_course.append(g)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "len(grades_per_course)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades_per_course[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Now append them all together (concatenate)\n",
    "result = pd.concat( grades_per_course, ignore_index=True)\n",
    "result.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result[result.Course=='EPA101']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Merge the 2 student names and grades together\n",
    "grades=pd.merge(student,result,how=\"left\")\n",
    "grades.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column with the mean of the tests\n",
    "grades['Final'] = grades.ix[:,'Test1':'Test4'].mean(axis=1)\n",
    "grades.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create extra columne 'Passed'\n",
    "grades['Passed'] = np.where( grades['Final']>=5.8, True, False)\n",
    "grades.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many passed/failed?\n",
    "pd.value_counts(grades['Passed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades['Final'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades['Final'].plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
